{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briceshun/Documents/Personal Projects/rag-test/.venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/briceshun/Documents/Personal Projects/rag-test/.venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/briceshun/Documents/Personal Projects/rag-test/.venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/briceshun/Documents/Personal Projects/rag-test/.venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/briceshun/Documents/Personal Projects/rag-test/.venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "from agents import load_model\n",
    "from agents import prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database replica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples and Info Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List tables\n",
    "l_tables = db.get_usable_table_names()\n",
    "\n",
    "# Create metadata\n",
    "d_metadata = {}\n",
    "for table in l_tables:\n",
    "    # Sample 10 rows from each table\n",
    "    sample = db.run(f\"SELECT * FROM {table} LIMIT 5;\", fetch=\"cursor\")\n",
    "    # Get table schema\n",
    "    infoschema = db.run(f\"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table}';\", fetch=\"cursor\")\n",
    "    # Store metadata\n",
    "    d_metadata[table] = {\n",
    "        \"sample\": list(sample.mappings()),\n",
    "        \"infoschema\": list(infoschema.mappings())[0]['sql'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenAI Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa352db145f94d0ea5424c625144c3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, pipe = load_model('Llama-3_2-3B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an AI model trained to analyze database schemas and provide detailed descriptions. \n",
    "Given the following table sample and information schema, please:\n",
    "\n",
    "1. Write a short description the table, including its columns and data types. BE SIMPLE AND CONCISE.\n",
    "2. Suggest the main use case for this table in a database.\n",
    "\n",
    "I will provide you with the following information:\n",
    "{   \"sample\": \"...\",\n",
    "    \"schema\": \"...\",\n",
    "}\n",
    "\n",
    "Please provide a detailed and structured response with no code formatting using the following format:\n",
    "{   \"description\": '...\",\n",
    "    \"use case\": '...\",\n",
    "}\n",
    "\"\"\"\n",
    "system_prompt = prompts.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Album\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Artist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Customer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Employee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Genre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Invoice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: InvoiceLine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: MediaType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Playlist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing table Playlist: Expecting ',' delimiter: line 3 column 207 (char 513)\n",
      "Retrying... (1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: PlaylistTrack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "for table in l_tables:\n",
    "    print(f\"Processing table: {table}\")\n",
    "    # Generate response\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"{d_metadata[table]}\"},\n",
    "    ]\n",
    "    response = pipe(messages)\n",
    "\n",
    "    # Clean response\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = pipe(messages)\n",
    "            json_string = response[0]['generated_text'][2]['content'].replace(\"'\", '\"')\n",
    "            data_dict = json.loads(json_string)\n",
    "            break  # Exit loop if successful\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing table {table}: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                raise  # Re-raise the exception if max retries reached\n",
    "            print(f\"Retrying... ({attempt + 1}/{max_retries})\")\n",
    "\n",
    "    # Store metadata\n",
    "    d_metadata[table]['description'] = data_dict['description']\n",
    "    d_metadata[table]['use case'] = data_dict['use case']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RowMapping to Dict\n",
    "for table in l_tables:\n",
    "    d_metadata[table]['sample'] = [dict(row) for row in d_metadata[table]['sample']]\n",
    "\n",
    "# Save dictionary to a JSON file\n",
    "with open('data/metadata.json', 'w') as json_file:\n",
    "    json.dump(d_metadata, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/metadata.json', 'r') as json_file:\n",
    "    d_metadata = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text files\n",
    "for table in l_tables:\n",
    "    with open(f'data/metadata/{table}.txt', 'w') as txt_file:\n",
    "        txt_file.write(f\"\\n\\nTable: {table}\\n\\n\")\n",
    "        txt_file.write(f\"Description: \\n{d_metadata[table]['description']}\\n\\n\")\n",
    "        txt_file.write(f\"Use Case: \\n{d_metadata[table]['use case']}\\n\\n\")\n",
    "        txt_file.write(f\"Schema: \\n{d_metadata[table]['infoschema']}\\n\\n\")\n",
    "        txt_file.write(f\"Sample:\\n\")\n",
    "        for row in d_metadata[table]['sample']:\n",
    "            txt_file.write(f\"{row}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"data/storage\"\n",
    "    )\n",
    "    db_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not index_loaded:\n",
    "    # load data\n",
    "    chinook_metadata = SimpleDirectoryReader(\n",
    "        input_files=[f'data/metadata/{table}.txt' for table in l_tables]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    chinook_index = VectorStoreIndex.from_documents(\n",
    "        chinook_metadata, \n",
    "        embed_model=HuggingFaceEmbedding(\n",
    "            model_name=\"BAAI/bge-small-en-v1.5\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # persist index\n",
    "    chinook_index.storage_context.persist(persist_dir=\"data/storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_engine = chinook_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = db_engine.retrieve(\"Which album has the most tracks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Table: Album\\n\\nDescription: \\nThe Album table contains information about albums, including the album ID, title, and the ID of the artist who created it. The album ID uniquely identifies each album, and the artist ID establishes a foreign key relationship with the Artist table. The title is limited to 160 characters.\\n\\nUse Case: \\nThe main use case for this table is to store and manage information about albums, including their titles, artist IDs, and album IDs, allowing for efficient querying and retrieval of album data in conjunction with artist data.\\n\\nSchema: \\nCREATE TABLE [Album]\\n(\\n    [AlbumId] INTEGER  NOT NULL,\\n    [Title] NVARCHAR(160)  NOT NULL,\\n    [ArtistId] INTEGER  NOT NULL,\\n    CONSTRAINT [PK_Album] PRIMARY KEY  ([AlbumId]),\\n    FOREIGN KEY ([ArtistId]) REFERENCES [Artist] ([ArtistId]) \\n\\t\\tON DELETE NO ACTION ON UPDATE NO ACTION\\n)\\n\\nSample:\\n{'AlbumId': 1, 'Title': 'For Those About To Rock We Salute You', 'ArtistId': 1}\\n{'AlbumId': 2, 'Title': 'Balls to the Wall', 'ArtistId': 2}\\n{'AlbumId': 3, 'Title': 'Restless and Wild', 'ArtistId': 2}\\n{'AlbumId': 4, 'Title': 'Let There Be Rock', 'ArtistId': 1}\\n{'AlbumId': 5, 'Title': 'Big Ones', 'ArtistId': 3}\\nTable: Track\\n\\nDescription: \\nThe Track table stores information about individual music tracks, including track ID, name, album ID, media type ID, genre ID, composer, milliseconds, bytes, and unit price. The table has foreign key constraints to maintain relationships with the Album and Genre tables.\\n\\nUse Case: \\nThe main use case for this table is to manage and store information about individual music tracks, enabling the retrieval and manipulation of track data in a database.\\n\\nSchema: \\nCREATE TABLE [Track]\\n(\\n    [TrackId] INTEGER  NOT NULL,\\n    [Name] NVARCHAR(200)  NOT NULL,\\n    [AlbumId] INTEGER,\\n    [MediaTypeId] INTEGER  NOT NULL,\\n    [GenreId] INTEGER,\\n    [Composer] NVARCHAR(220),\\n    [Milliseconds] INTEGER  NOT NULL,\\n    [Bytes] INTEGER,\\n    [UnitPrice] NUMERIC(10,2)  NOT NULL,\\n    CONSTRAINT [PK_Track] PRIMARY KEY  ([TrackId]),\\n    FOREIGN KEY ([AlbumId]) REFERENCES [Album] ([AlbumId]) \\n\\t\\tON DELETE NO ACTION ON UPDATE NO ACTION,\\n    FOREIGN KEY ([GenreId]) REFERENCES [Genre] ([GenreId]) \\n\\t\\tON DELETE NO ACTION ON UPDATE NO ACTION,\\n    FOREIGN KEY ([MediaTypeId]) REFERENCES [MediaType] ([MediaTypeId]) \\n\\t\\tON DELETE NO ACTION ON UPDATE NO ACTION\\n)\\n\\nSample:\\n{'TrackId': 1, 'Name': 'For Those About To Rock (We Salute You)', 'AlbumId': 1, 'MediaTypeId': 1, 'GenreId': 1, 'Composer': 'Angus Young, Malcolm Young, Brian Johnson', 'Milliseconds': 343719, 'Bytes': 11170334, 'UnitPrice': 0.99}\\n{'TrackId': 2, 'Name': 'Balls to the Wall', 'AlbumId': 2, 'MediaTypeId': 2, 'GenreId': 1, 'Composer': 'U. Dirkschneider, W. Hoffmann, H. Frank, P. Baltes, S. Kaufmann, G. Hoffmann', 'Milliseconds': 342562, 'Bytes': 5510424, 'UnitPrice': 0.99}\\n{'TrackId': 3, 'Name': 'Fast As a Shark', 'AlbumId': 3, 'MediaTypeId': 2, 'GenreId': 1, 'Composer': 'F. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman', 'Milliseconds': 230619, 'Bytes': 3990994, 'UnitPrice': 0.99}\\n{'TrackId': 4, 'Name': 'Restless and Wild', 'AlbumId': 3, 'MediaTypeId': 2, 'GenreId': 1, 'Composer': 'F. Baltes, R.A. Smith-Diesel, S. Kaufman, U. Dirkscneider & W. Hoffman', 'Milliseconds': 252051, 'Bytes': 4331779, 'UnitPrice': 0.99}\\n{'TrackId': 5, 'Name': 'Princess of the Dawn', 'AlbumId': 3, 'MediaTypeId': 2, 'GenreId': 1, 'Composer': 'Deaffy & R.A. Smith-Diesel', 'Milliseconds': 375418, 'Bytes': 6290521, 'UnitPrice': 0.99}\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\n'.join([t.text for t in tables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_prompt = \"Write a SQL query using the information provided. Only return the query, do not explain it.\"\n",
    "prompt = \"Which album has the most tracks?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": sql_prompt},\n",
    "        {\"role\": \"sqlagent\", \"content\": '\\n'.join([t.text for t in tables])},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "response = pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = response[0]['generated_text'][3]['content'].replace('```sql', '').replace('```', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Greatest Hits', 57)]\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(fr\"\"\"{query}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
